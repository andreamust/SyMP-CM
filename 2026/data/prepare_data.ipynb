{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59de8069",
   "metadata": {},
   "source": [
    "# Data Preparation \n",
    "\n",
    "This notebook contains code for downloading and preprocessing data to be used in all \n",
    "sessions of the course.\n",
    "\n",
    "Copyright-free data will be shared in the repository, so you won't need to run this \n",
    "notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f235c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Set seed for reproducibility\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "037ff74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global variables\n",
    "SAMPLE_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a10ff3",
   "metadata": {},
   "source": [
    "## MIDI Dataset\n",
    "As main MIDI dataset for the course, we will use the [Lakh MIDI Dataset (LMD)](https://colinraffel.com/projects/lmd/), a collection of 176,581 unique MIDI files.\n",
    "We will use the cleaned subset of the dataset, which contains 45,129 files, which is \n",
    "available for download on [Kaggle](https://www.kaggle.com/datasets/imsparsh/lakh-midi-clean).\n",
    "\n",
    "For the sake of simplicity, we will create a subset of the dataset containing only 100 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523e4b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define varaibles\n",
    "MIDI_DATASET_PATH = Path(\"./midi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77ff61ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading to /Users/andreapoltronieri/.cache/kagglehub/datasets/imsparsh/lakh-midi-clean/1.archive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226M/226M [00:06<00:00, 37.7MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/andreapoltronieri/.cache/kagglehub/datasets/imsparsh/lakh-midi-clean/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"imsparsh/lakh-midi-clean\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37a6e3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 100 MIDI files to /Users/andreapoltronieri/Documents/Projects/SyMP-CM/2026/data/midi\n"
     ]
    }
   ],
   "source": [
    "# The dataset is organized in folders by track names. We'll iterate through all folders\n",
    "# and collect MIDI files.\n",
    "\n",
    "MIDI_DATASET_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "all_midi_files = list(Path(path).rglob(\"*.mid\"))\n",
    "\n",
    "# Sample a subset of files\n",
    "sampled_files = random.sample(all_midi_files, SAMPLE_SIZE)\n",
    "for midi_file in sampled_files:\n",
    "    destination = MIDI_DATASET_PATH / midi_file.name\n",
    "    shutil.copy(midi_file, destination)\n",
    "\n",
    "print(f\"Sampled {SAMPLE_SIZE} MIDI files to {MIDI_DATASET_PATH.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b43b1e3",
   "metadata": {},
   "source": [
    "## MusicXML Dataset\n",
    "\n",
    "As MusicXML dataset, we will use a subset of [PDMX](https://zenodo.org/records/13763756), a large collection (~250k) of public domain MusicXML files from [musescore.com](https://musescore.com/).\n",
    "\n",
    "We will use a small subset of the dataset containing only 100 files. The dataset id available for download on [Zenodo](https://zenodo.org/record/13763756). First, we will download the dataset and extract the files. Use the dataset path in code block below to allow processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048a6dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables for MusicXML dataset\n",
    "ZENODO_DATASET_PATH = Path(\"/home/must/Documents/PDMX/mxl\")\n",
    "\n",
    "MUSICXML_DATASET_PATH = Path(\"./musicxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0913ef99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 254035 MusicXML files in /home/must/Documents/PDMX/mxl\n",
      "Sampled 100 MusicXML files to /home/must/Projects/SyMP-CM/2026/data/musicxml\n"
     ]
    }
   ],
   "source": [
    "MUSICXML_DATASET_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "# iterate over all folders and subfolders to collect MusicXML files\n",
    "all_musicxml_files = list(ZENODO_DATASET_PATH.rglob(\"*.mxl\"))\n",
    "print(\n",
    "    f\"Found {len(all_musicxml_files)} MusicXML files in {ZENODO_DATASET_PATH.resolve()}\"\n",
    ")\n",
    "\n",
    "# Sample a subset of files\n",
    "sampled_musicxml_files = random.sample(all_musicxml_files, SAMPLE_SIZE)\n",
    "\n",
    "for musicxml_file in sampled_musicxml_files:\n",
    "    destination = MUSICXML_DATASET_PATH / musicxml_file.name\n",
    "    shutil.copy(musicxml_file, destination)\n",
    "\n",
    "print(f\"Sampled {SAMPLE_SIZE} MusicXML files to {MUSICXML_DATASET_PATH.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29edf50d",
   "metadata": {},
   "source": [
    "## ABC Dataset\n",
    "\n",
    "As ABC notation dataset, we will use the [Nottingham dataset](http://abc.sourceforge.net/NMD/), a collection of folk tunes in ABC notation format.\n",
    "\n",
    "For simplicity, we'll download the dataset from [Kaggle](https://www.kaggle.com/datasets/tishyatripathi/nottingham-music-dataset), which contains 1200 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73f0a0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables for ABC dataset\n",
    "ABC_DATASET_PATH = Path(\"./abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "136685c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/must/.cache/kagglehub/datasets/tishyatripathi/nottingham-music-dataset/versions/2\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"tishyatripathi/nottingham-music-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "741c449a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 338 tunes in the Nottingham dataset.\n"
     ]
    }
   ],
   "source": [
    "# Parse the datset, which is a single .txt file containing all tunes\n",
    "nottingham_txt_file = Path(path) / \"input_revised.txt\"\n",
    "\n",
    "# Read the file and split tunes by \"X:\" which indicates the start of a new tune\n",
    "with open(nottingham_txt_file, \"r\") as f:\n",
    "    content = f.read()\n",
    "tunes = content.split(\"\\nX:\")[1:]  # Skip the first empty split\n",
    "print(f\"Found {len(tunes)} tunes in the Nottingham dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65177790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 100 ABC files to /home/must/Projects/SyMP-CM/2026/data/abc\n"
     ]
    }
   ],
   "source": [
    "# Randomply sample a subset of tunes\n",
    "sampled_tunes = random.sample(tunes, SAMPLE_SIZE)\n",
    "\n",
    "# Save sampled tunes to individual .abc files\n",
    "ABC_DATASET_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "for i, tune in enumerate(sampled_tunes):\n",
    "    abc_file = ABC_DATASET_PATH / f\"tune_{i + 1}.abc\"\n",
    "    with open(abc_file, \"w\") as f:\n",
    "        f.write(\"X:\" + tune)  # Add back the \"X:\" prefix\n",
    "print(f\"Sampled {SAMPLE_SIZE} ABC files to {ABC_DATASET_PATH.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
